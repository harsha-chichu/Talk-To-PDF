# ğŸ“š Chat with Multiple PDFs (RAG + Streamlit + LLM)

## ğŸš€ Overview
This project is an **AI-powered PDF Q&A application** built with **Streamlit, LangChain, OpenAI, and FAISS**.  
It allows users to **upload multiple PDFs**, process them into embeddings, and then **chat with the documents** using natural language queries.

The system ensures that answers are **strictly derived from the uploaded PDFs**, preventing hallucinations by returning:
> "This question is not related to the uploaded PDFs."  
when asked something outside the context.

## How It Works
<img width="2684" height="1489" alt="image" src="https://github.com/user-attachments/assets/30dc8198-c80d-4a54-b0be-c9a68161e317" />

---

## âœ¨ Features
- ğŸ“‚ Upload multiple PDFs simultaneously
- ğŸ” Split documents into semantic chunks for better retrieval
- ğŸ§  Generate vector embeddings using OpenAI Embeddings
- âš¡ Store and retrieve embeddings via FAISS vectorstore
- ğŸ¤– Chat interface powered by LangChainâ€™s `ConversationalRetrievalChain`
- ğŸ¨ Custom UI with **dark mode compatibility** for readability
- â›” Strict filtering â€“ no hallucinated answers
- ğŸ•’ Timestamped chat history for clarity

---

## ğŸ› ï¸ Tech Stack
- [Streamlit](https://streamlit.io/) â€“ UI framework  
- [LangChain](https://www.langchain.com/) â€“ Orchestration for RAG pipeline  
- [OpenAI API](https://platform.openai.com/) â€“ LLM + embeddings  
- [FAISS](https://faiss.ai/) â€“ Vector database for similarity search  
- [PyPDFLoader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf) â€“ PDF document loader  

---

## âš™ï¸ How It Works
1. **Upload PDFs** â€“ User uploads one or more PDFs via the sidebar.  
2. **Processing** â€“ The PDFs are split into text chunks and embedded using OpenAI.  
3. **Vectorstore** â€“ FAISS stores the embeddings for fast retrieval.  
4. **Chat** â€“ User asks a question â†’ system retrieves the most relevant chunks â†’ LLM generates a contextual answer.  
5. **Response Filtering** â€“ If the answer is not found in the documents, a strict fallback is triggered.  

---

## ğŸ’» Installation

### 1. Clone the repository
```bash
git clone https://github.com/harsha-chichu/Talk-To-PDF.git
cd Talk-To-PDF
```

### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate    # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set up environment variables
Create a `.env` file and add:
```bash
OPENAI_API_KEY=your_openai_api_key
```

### 5. Run the app
```bash
streamlit run app.py
```

---

## ğŸ“¸ Screenshots
![UI](image.png)

---

## ğŸ”® Future Improvements
- âœ… Support for other file formats (Word, Excel, TXT)
- âœ… Option to download chat history
- âœ… Advanced filtering (multi-turn reasoning, hybrid search)
- âœ… Deployment on cloud (Streamlit Cloud, Vercel, Render, etc.)

---

## ğŸ‘¤ Author
**Harsha Vardhan**  
AI Engineer | Researcher | Builder of practical AI tools  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/harsha-vardhan12/) | [GitHub](https://github.com/harsha-chichu)

---

## â­ Contribute & Support
If you find this project helpful, give it a â­ on GitHub and share it with others!
